{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv('/content/train.csv', encoding='latin1')\n",
        "test_df = pd.read_csv('/content/test.csv', encoding='latin1')\n",
        "\n",
        "\n",
        "print(\"Train sentiment classes:\")\n",
        "print(train_df['sentiment'].unique())\n",
        "print(test_df['sentiment'].unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFyUuzKCQ4LR",
        "outputId": "0eb2bc16-417e-47ae-e542-6c069bf1006a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train sentiment classes:\n",
            "['neutral' 'negative' 'positive']\n",
            "['neutral' 'positive' 'negative' nan]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train DataFrame shape:\", train_df.shape)\n",
        "print(\"Test DataFrame shape:\", test_df.shape)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8EC4vh31QnzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train DataFrame info:\")\n",
        "train_df.info()\n",
        "\n",
        "print(\"Test DataFrame info:\")\n",
        "test_df.info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vKXzuVsgQ4lS",
        "outputId": "98defe6d-71d6-4c25-813d-98a248413839"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train DataFrame info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27481 entries, 0 to 27480\n",
            "Data columns (total 10 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   textID            27481 non-null  object \n",
            " 1   text              27480 non-null  object \n",
            " 2   selected_text     27480 non-null  object \n",
            " 3   sentiment         27481 non-null  object \n",
            " 4   Time of Tweet     27481 non-null  object \n",
            " 5   Age of User       27481 non-null  object \n",
            " 6   Country           27481 non-null  object \n",
            " 7   Population -2020  27481 non-null  int64  \n",
            " 8   Land Area (Km²)   27481 non-null  float64\n",
            " 9   Density (P/Km²)   27481 non-null  int64  \n",
            "dtypes: float64(1), int64(2), object(7)\n",
            "memory usage: 2.1+ MB\n",
            "Test DataFrame info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4815 entries, 0 to 4814\n",
            "Data columns (total 9 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   textID            3534 non-null   object \n",
            " 1   text              3534 non-null   object \n",
            " 2   sentiment         3534 non-null   object \n",
            " 3   Time of Tweet     3534 non-null   object \n",
            " 4   Age of User       3534 non-null   object \n",
            " 5   Country           3534 non-null   object \n",
            " 6   Population -2020  3534 non-null   float64\n",
            " 7   Land Area (Km²)   3534 non-null   float64\n",
            " 8   Density (P/Km²)   3534 non-null   float64\n",
            "dtypes: float64(3), object(6)\n",
            "memory usage: 338.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "\n",
        "train_df = pd.read_csv('/content/train.csv', encoding='latin1')\n",
        "test_df = pd.read_csv('/content/test.csv', encoding='latin1')\n",
        "\n",
        "\n",
        "train_df.dropna(subset=['text', 'selected_text'], inplace=True)\n",
        "test_df['text'].fillna('', inplace=True)\n",
        "test_df['sentiment'].fillna('neutral', inplace=True)\n",
        "test_df['Country'].fillna('Unknown', inplace=True)\n",
        "test_df['Population -2020'].fillna(test_df['Population -2020'].mean(), inplace=True)\n",
        "test_df['Land Area (Km²)'].fillna(test_df['Land Area (Km²)'].mean(), inplace=True)\n",
        "test_df['Density (P/Km²)'].fillna(test_df['Density (P/Km²)'].mean(), inplace=True)\n",
        "most_common_time_of_tweet = test_df['Time of Tweet'].mode()[0] if not test_df['Time of Tweet'].mode().empty else 'Unknown'\n",
        "test_df['Time of Tweet'].fillna(most_common_time_of_tweet, inplace=True)\n",
        "most_common_age_of_user = test_df['Age of User'].mode()[0] if not test_df['Age of User'].mode().empty else 'Unknown'\n",
        "test_df['Age of User'].fillna(most_common_age_of_user, inplace=True)\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(train_df['sentiment'])\n",
        "y_test = label_encoder.transform(test_df['sentiment'])\n",
        "\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train = vectorizer.fit_transform(train_df['text'])\n",
        "X_test = vectorizer.transform(test_df['text'])\n",
        "\n",
        "\n",
        "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "\n",
        "print(\"Logistic Regression Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "F1lL2V-sqT1B",
        "outputId": "0efeccea-f8de-41a2-8c0b-16afb5c5f814"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.73      0.64      0.68      1001\n",
            "     neutral       0.80      0.87      0.83      2711\n",
            "    positive       0.81      0.71      0.76      1103\n",
            "\n",
            "    accuracy                           0.79      4815\n",
            "   macro avg       0.78      0.74      0.76      4815\n",
            "weighted avg       0.79      0.79      0.78      4815\n",
            "\n",
            "Accuracy: 0.7875389408099689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "log_reg = LogisticRegression(random_state=42)\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "print(\"Best parameters found: \", best_params)\n",
        "print(\"Best cross-validation accuracy: {:.2f}\".format(best_score))\n",
        "\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "38rAoxX1qmDn",
        "outputId": "f133cba3-18fb-49ce-fe54-8570b0399952"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found:  {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best cross-validation accuracy: 0.71\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.76      0.64      0.69      1001\n",
            "     neutral       0.80      0.88      0.84      2711\n",
            "    positive       0.81      0.74      0.77      1103\n",
            "\n",
            "    accuracy                           0.80      4815\n",
            "   macro avg       0.79      0.75      0.77      4815\n",
            "weighted avg       0.79      0.80      0.79      4815\n",
            "\n",
            "Accuracy: 0.7958463136033229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_y_pred = rf_model.predict(X_test)\n",
        "\n",
        "print(\"Random Forest Classification Report:\")\n",
        "print(classification_report(y_test, rf_y_pred, target_names=label_encoder.classes_))\n",
        "print(\"Accuracy with Random Forest:\", accuracy_score(y_test, rf_y_pred))\n",
        "\n",
        "\n",
        "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "gb_model.fit(X_train, y_train)\n",
        "gb_y_pred = gb_model.predict(X_test)\n",
        "\n",
        "print(\"Gradient Boosting Classification Report:\")\n",
        "print(classification_report(y_test, gb_y_pred, target_names=label_encoder.classes_))\n",
        "print(\"Accuracy with Gradient Boosting:\", accuracy_score(y_test, gb_y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "po1_Qnk8rRCb",
        "outputId": "160bade8-0a24-4cc5-bea7-a026a2141e4b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.73      0.57      0.64      1001\n",
            "     neutral       0.78      0.88      0.82      2711\n",
            "    positive       0.79      0.70      0.74      1103\n",
            "\n",
            "    accuracy                           0.77      4815\n",
            "   macro avg       0.77      0.71      0.73      4815\n",
            "weighted avg       0.77      0.77      0.77      4815\n",
            "\n",
            "Accuracy with Random Forest: 0.7717549325025961\n",
            "Gradient Boosting Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.78      0.40      0.53      1001\n",
            "     neutral       0.71      0.92      0.80      2711\n",
            "    positive       0.82      0.58      0.68      1103\n",
            "\n",
            "    accuracy                           0.74      4815\n",
            "   macro avg       0.77      0.64      0.67      4815\n",
            "weighted avg       0.75      0.74      0.72      4815\n",
            "\n",
            "Accuracy with Gradient Boosting: 0.7362409138110073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, SpatialDropout1D\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(train_df['text'])\n",
        "X_train_seq = tokenizer.texts_to_sequences(train_df['text'])\n",
        "X_test_seq = tokenizer.texts_to_sequences(test_df['text'])\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=100)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=100)\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(train_df['sentiment'])\n",
        "y_test_encoded = label_encoder.transform(test_df['sentiment'])\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(5000, 128, input_length=100))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit(X_train_pad, y_train_encoded, epochs=5, batch_size=64, validation_data=(X_test_pad, y_test_encoded))\n",
        "\n",
        "\n",
        "y_pred_prob = model.predict(X_test_pad)\n",
        "y_pred = y_pred_prob.argmax(axis=1)\n",
        "\n",
        "print(\"LSTM Classification Report:\")\n",
        "print(classification_report(y_test_encoded, y_pred, target_names=label_encoder.classes_))\n",
        "print(\"Accuracy with LSTM:\", accuracy_score(y_test_encoded, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vEuY4tnTrThV",
        "outputId": "d23eb272-8519-4504-93e3-c5b8406416bb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 218ms/step - accuracy: 0.5208 - loss: 0.9481 - val_accuracy: 0.7807 - val_loss: 0.5969\n",
            "Epoch 2/5\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 223ms/step - accuracy: 0.7461 - loss: 0.6237 - val_accuracy: 0.7988 - val_loss: 0.5360\n",
            "Epoch 3/5\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 217ms/step - accuracy: 0.7805 - loss: 0.5441 - val_accuracy: 0.8048 - val_loss: 0.5274\n",
            "Epoch 4/5\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 213ms/step - accuracy: 0.7976 - loss: 0.5117 - val_accuracy: 0.8046 - val_loss: 0.5336\n",
            "Epoch 5/5\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 216ms/step - accuracy: 0.8197 - loss: 0.4675 - val_accuracy: 0.8004 - val_loss: 0.5657\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step\n",
            "LSTM Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.71      0.74      0.72      1001\n",
            "     neutral       0.83      0.84      0.84      2711\n",
            "    positive       0.81      0.76      0.78      1103\n",
            "\n",
            "    accuracy                           0.80      4815\n",
            "   macro avg       0.78      0.78      0.78      4815\n",
            "weighted avg       0.80      0.80      0.80      4815\n",
            "\n",
            "Accuracy with LSTM: 0.8004153686396677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "model.save('lstm_model.keras')\n",
        "\n"
      ],
      "metadata": {
        "id": "V2GKfcMpvuud"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s32rvBHdxfN6",
        "outputId": "180d0ddb-72ad-413e-bd36-2dac519068fe"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense\n"
      ],
      "metadata": {
        "id": "Hnsrtj_ExlR1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy pandas scikit-learn\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUwhTdmSxp7j",
        "outputId": "7705f7d5-f14c-465f-afa8-12393f9f8de4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense\n",
        "\n",
        "\n",
        "vocab_size = 5000\n",
        "embedding_dim = 50\n",
        "max_length = 100\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(train_df['text'])\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(train_df['text'])\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=max_length)\n",
        "\n",
        "X_test_seq = tokenizer.texts_to_sequences(test_df['text'])\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=max_length)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\n",
        "model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(X_train_padded, y_train, epochs=5, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyADZA2Hxq-a",
        "outputId": "316b0db0-c622-430d-a96f-297a12474c63"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 33ms/step - accuracy: 0.5141 - loss: 0.9574 - val_accuracy: 0.6961 - val_loss: 0.7095\n",
            "Epoch 2/5\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 24ms/step - accuracy: 0.7494 - loss: 0.6221 - val_accuracy: 0.7182 - val_loss: 0.6915\n",
            "Epoch 3/5\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 24ms/step - accuracy: 0.8143 - loss: 0.4948 - val_accuracy: 0.7021 - val_loss: 0.7409\n",
            "Epoch 4/5\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 24ms/step - accuracy: 0.8694 - loss: 0.3749 - val_accuracy: 0.6890 - val_loss: 0.8433\n",
            "Epoch 5/5\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 24ms/step - accuracy: 0.9197 - loss: 0.2526 - val_accuracy: 0.6729 - val_loss: 0.9773\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f57f642e440>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('my_model.keras')"
      ],
      "metadata": {
        "id": "QizLZxTByU_C"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}